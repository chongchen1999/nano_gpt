{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dfdc7c84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of dataset in characters: 1115394\n"
     ]
    }
   ],
   "source": [
    "with open('input.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "\n",
    "print('length of dataset in characters:', len(text))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34315711",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You are all resolved rather to die than to famish?\n",
      "\n",
      "All:\n",
      "Resolved. resolved.\n",
      "\n",
      "First Citizen:\n",
      "First, you know Caius Marcius is chief enemy to the people.\n",
      "\n",
      "All:\n",
      "We know't, we know't.\n",
      "\n",
      "First Citizen:\n",
      "Let us kill him, and we'll have corn at our own price.\n",
      "Is't a verdict?\n",
      "\n",
      "All:\n",
      "No more talking on't; let it be done: away, away!\n",
      "\n",
      "Second Citizen:\n",
      "One word, good citizens.\n",
      "\n",
      "First Citizen:\n",
      "We are accounted poor citizens, the patricians good.\n",
      "What authority surfeits on would relieve us: if they\n",
      "would yield us but the superfluity, while it were\n",
      "wholesome, we might guess they relieved us humanely;\n",
      "but they think we are too dear: the leanness that\n",
      "afflicts us, the object of our misery, is as an\n",
      "inventory to particularise their abundance; our\n",
      "sufferance is a gain to them Let us revenge this with\n",
      "our pikes, ere we become rakes: for the gods know I\n",
      "speak this in hunger for bread, not in thirst for revenge.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(text[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94b67544",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab size: 65\n",
      "all unique characters: \n",
      " !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "n_embed = len(chars)\n",
    "print('vocab size:', n_embed)\n",
    "print('all unique characters:', ''.join(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "025d0ef2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[46, 47, 47, 1, 58, 46, 43, 56, 43]\n",
      "hii there\n"
     ]
    }
   ],
   "source": [
    "# create a mapping from characters to integers\n",
    "stoi = { ch:i for i,ch in enumerate(chars) } # string to integer\n",
    "itos = { i:ch for i,ch in enumerate(chars) } # integer to string\n",
    "def encode(s):\n",
    "    \"\"\"encode a string to a list of integers\"\"\"\n",
    "    return [stoi[c] for c in s]\n",
    "\n",
    "def decode(int_list):\n",
    "    \"\"\"decode a list of integers to a string\"\"\"\n",
    "    return ''.join([itos[i] for i in int_list])\n",
    "\n",
    "print(encode('hii there'))\n",
    "print(decode(encode('hii there')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "55f0f598",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data type: <class 'torch.Tensor'>\n",
      "data shape: torch.Size([1115394])\n",
      "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
      "        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,\n",
      "         1, 44, 59, 56, 58, 46, 43, 56,  6,  1, 46, 43, 39, 56,  1, 51, 43,  1,\n",
      "        57, 54, 43, 39, 49,  8,  0,  0, 13, 50, 50, 10,  0, 31, 54, 43, 39, 49,\n",
      "         6,  1, 57, 54, 43, 39, 49,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47,\n",
      "        58, 47, 64, 43, 52, 10,  0, 37, 53, 59,  1, 39, 56, 43,  1, 39, 50, 50,\n",
      "         1, 56, 43, 57, 53, 50, 60, 43, 42,  1, 56, 39, 58, 46, 43, 56,  1, 58,\n",
      "        53,  1, 42, 47, 43,  1, 58, 46, 39, 52,  1, 58, 53,  1, 44, 39, 51, 47,\n",
      "        57, 46, 12,  0,  0, 13, 50, 50, 10,  0, 30, 43, 57, 53, 50, 60, 43, 42,\n",
      "         8,  1, 56, 43, 57, 53, 50, 60, 43, 42,  8,  0,  0, 18, 47, 56, 57, 58,\n",
      "         1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 18, 47, 56, 57, 58,  6,  1, 63,\n",
      "        53, 59,  1, 49, 52, 53, 61,  1, 15, 39, 47, 59, 57,  1, 25, 39, 56, 41,\n",
      "        47, 59, 57,  1, 47, 57,  1, 41, 46, 47, 43, 44,  1, 43, 52, 43, 51, 63,\n",
      "         1, 58, 53,  1, 58, 46, 43,  1, 54, 43, 53, 54, 50, 43,  8,  0,  0, 13,\n",
      "        50, 50, 10,  0, 35, 43,  1, 49, 52, 53, 61,  5, 58,  6,  1, 61, 43,  1,\n",
      "        49, 52, 53, 61,  5, 58,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47, 58,\n",
      "        47, 64, 43, 52, 10,  0, 24, 43, 58,  1, 59, 57,  1, 49, 47, 50, 50,  1,\n",
      "        46, 47, 51,  6,  1, 39, 52, 42,  1, 61, 43,  5, 50, 50,  1, 46, 39, 60,\n",
      "        43,  1, 41, 53, 56, 52,  1, 39, 58,  1, 53, 59, 56,  1, 53, 61, 52,  1,\n",
      "        54, 56, 47, 41, 43,  8,  0, 21, 57,  5, 58,  1, 39,  1, 60, 43, 56, 42,\n",
      "        47, 41, 58, 12,  0,  0, 13, 50, 50, 10,  0, 26, 53,  1, 51, 53, 56, 43,\n",
      "         1, 58, 39, 50, 49, 47, 52, 45,  1, 53, 52,  5, 58, 11,  1, 50, 43, 58,\n",
      "         1, 47, 58,  1, 40, 43,  1, 42, 53, 52, 43, 10,  1, 39, 61, 39, 63,  6,\n",
      "         1, 39, 61, 39, 63,  2,  0,  0, 31, 43, 41, 53, 52, 42,  1, 15, 47, 58,\n",
      "        47, 64, 43, 52, 10,  0, 27, 52, 43,  1, 61, 53, 56, 42,  6,  1, 45, 53,\n",
      "        53, 42,  1, 41, 47, 58, 47, 64, 43, 52, 57,  8,  0,  0, 18, 47, 56, 57,\n",
      "        58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 35, 43,  1, 39, 56, 43,  1,\n",
      "        39, 41, 41, 53, 59, 52, 58, 43, 42,  1, 54, 53, 53, 56,  1, 41, 47, 58,\n",
      "        47, 64, 43, 52, 57,  6,  1, 58, 46, 43,  1, 54, 39, 58, 56, 47, 41, 47,\n",
      "        39, 52, 57,  1, 45, 53, 53, 42,  8,  0, 35, 46, 39, 58,  1, 39, 59, 58,\n",
      "        46, 53, 56, 47, 58, 63,  1, 57, 59, 56, 44, 43, 47, 58, 57,  1, 53, 52,\n",
      "         1, 61, 53, 59, 50, 42,  1, 56, 43, 50, 47, 43, 60, 43,  1, 59, 57, 10,\n",
      "         1, 47, 44,  1, 58, 46, 43, 63,  0, 61, 53, 59, 50, 42,  1, 63, 47, 43,\n",
      "        50, 42,  1, 59, 57,  1, 40, 59, 58,  1, 58, 46, 43,  1, 57, 59, 54, 43,\n",
      "        56, 44, 50, 59, 47, 58, 63,  6,  1, 61, 46, 47, 50, 43,  1, 47, 58,  1,\n",
      "        61, 43, 56, 43,  0, 61, 46, 53, 50, 43, 57, 53, 51, 43,  6,  1, 61, 43,\n",
      "         1, 51, 47, 45, 46, 58,  1, 45, 59, 43, 57, 57,  1, 58, 46, 43, 63,  1,\n",
      "        56, 43, 50, 47, 43, 60, 43, 42,  1, 59, 57,  1, 46, 59, 51, 39, 52, 43,\n",
      "        50, 63, 11,  0, 40, 59, 58,  1, 58, 46, 43, 63,  1, 58, 46, 47, 52, 49,\n",
      "         1, 61, 43,  1, 39, 56, 43,  1, 58, 53, 53,  1, 42, 43, 39, 56, 10,  1,\n",
      "        58, 46, 43,  1, 50, 43, 39, 52, 52, 43, 57, 57,  1, 58, 46, 39, 58,  0,\n",
      "        39, 44, 44, 50, 47, 41, 58, 57,  1, 59, 57,  6,  1, 58, 46, 43,  1, 53,\n",
      "        40, 48, 43, 41, 58,  1, 53, 44,  1, 53, 59, 56,  1, 51, 47, 57, 43, 56,\n",
      "        63,  6,  1, 47, 57,  1, 39, 57,  1, 39, 52,  0, 47, 52, 60, 43, 52, 58,\n",
      "        53, 56, 63,  1, 58, 53,  1, 54, 39, 56, 58, 47, 41, 59, 50, 39, 56, 47,\n",
      "        57, 43,  1, 58, 46, 43, 47, 56,  1, 39, 40, 59, 52, 42, 39, 52, 41, 43,\n",
      "        11,  1, 53, 59, 56,  0, 57, 59, 44, 44, 43, 56, 39, 52, 41, 43,  1, 47,\n",
      "        57,  1, 39,  1, 45, 39, 47, 52,  1, 58, 53,  1, 58, 46, 43, 51,  1, 24,\n",
      "        43, 58,  1, 59, 57,  1, 56, 43, 60, 43, 52, 45, 43,  1, 58, 46, 47, 57,\n",
      "         1, 61, 47, 58, 46,  0, 53, 59, 56,  1, 54, 47, 49, 43, 57,  6,  1, 43,\n",
      "        56, 43,  1, 61, 43,  1, 40, 43, 41, 53, 51, 43,  1, 56, 39, 49, 43, 57,\n",
      "        10,  1, 44, 53, 56,  1, 58, 46, 43,  1, 45, 53, 42, 57,  1, 49, 52, 53,\n",
      "        61,  1, 21,  0, 57, 54, 43, 39, 49,  1, 58, 46, 47, 57,  1, 47, 52,  1,\n",
      "        46, 59, 52, 45, 43, 56,  1, 44, 53, 56,  1, 40, 56, 43, 39, 42,  6,  1,\n",
      "        52, 53, 58,  1, 47, 52,  1, 58, 46, 47, 56, 57, 58,  1, 44, 53, 56,  1,\n",
      "        56, 43, 60, 43, 52, 45, 43,  8,  0,  0])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "data = torch.tensor(encode(text), dtype=torch.long)\n",
    "\n",
    "print('data type:', type(data))\n",
    "print('data shape:', data.shape)\n",
    "print(data[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c6c00e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = int(len(data) * 0.9) # first 90% will be train, rest val\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f5ab9347",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block_size = 8 # the context length of a single example\n",
    "train_data[:block_size + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1b5567ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When input is tensor([18]), the target is 47\n",
      "When input is tensor([18, 47]), the target is 56\n",
      "When input is tensor([18, 47, 56]), the target is 57\n",
      "When input is tensor([18, 47, 56, 57]), the target is 58\n",
      "When input is tensor([18, 47, 56, 57, 58]), the target is 1\n",
      "When input is tensor([18, 47, 56, 57, 58,  1]), the target is 15\n",
      "When input is tensor([18, 47, 56, 57, 58,  1, 15]), the target is 47\n",
      "When input is tensor([18, 47, 56, 57, 58,  1, 15, 47]), the target is 58\n"
     ]
    }
   ],
   "source": [
    "x = train_data[:block_size] # input context\n",
    "y = train_data[1:block_size + 1] # targets are the same but shifted\n",
    "\n",
    "for t in range(block_size):\n",
    "    context = x[:t + 1] # input context\n",
    "    target = y[t] # target is the next character\n",
    "    print(f'When input is {context}, the target is {target}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2623d641",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:\n",
      "torch.Size([4, 8])\n",
      "tensor([[24, 43, 58,  5, 57,  1, 46, 43],\n",
      "        [44, 53, 56,  1, 58, 46, 39, 58],\n",
      "        [52, 58,  1, 58, 46, 39, 58,  1],\n",
      "        [25, 17, 27, 10,  0, 21,  1, 54]])\n",
      "targets:\n",
      "torch.Size([4, 8])\n",
      "tensor([[43, 58,  5, 57,  1, 46, 43, 39],\n",
      "        [53, 56,  1, 58, 46, 39, 58,  1],\n",
      "        [58,  1, 58, 46, 39, 58,  1, 46],\n",
      "        [17, 27, 10,  0, 21,  1, 54, 39]])\n",
      "**************************************************\n",
      "When input is tensor([24]), the target is 43\n",
      "When input is tensor([24, 43]), the target is 58\n",
      "When input is tensor([24, 43, 58]), the target is 5\n",
      "When input is tensor([24, 43, 58,  5]), the target is 57\n",
      "When input is tensor([24, 43, 58,  5, 57]), the target is 1\n",
      "When input is tensor([24, 43, 58,  5, 57,  1]), the target is 46\n",
      "When input is tensor([24, 43, 58,  5, 57,  1, 46]), the target is 43\n",
      "When input is tensor([24, 43, 58,  5, 57,  1, 46, 43]), the target is 39\n",
      "When input is tensor([44]), the target is 53\n",
      "When input is tensor([44, 53]), the target is 56\n",
      "When input is tensor([44, 53, 56]), the target is 1\n",
      "When input is tensor([44, 53, 56,  1]), the target is 58\n",
      "When input is tensor([44, 53, 56,  1, 58]), the target is 46\n",
      "When input is tensor([44, 53, 56,  1, 58, 46]), the target is 39\n",
      "When input is tensor([44, 53, 56,  1, 58, 46, 39]), the target is 58\n",
      "When input is tensor([44, 53, 56,  1, 58, 46, 39, 58]), the target is 1\n",
      "When input is tensor([52]), the target is 58\n",
      "When input is tensor([52, 58]), the target is 1\n",
      "When input is tensor([52, 58,  1]), the target is 58\n",
      "When input is tensor([52, 58,  1, 58]), the target is 46\n",
      "When input is tensor([52, 58,  1, 58, 46]), the target is 39\n",
      "When input is tensor([52, 58,  1, 58, 46, 39]), the target is 58\n",
      "When input is tensor([52, 58,  1, 58, 46, 39, 58]), the target is 1\n",
      "When input is tensor([52, 58,  1, 58, 46, 39, 58,  1]), the target is 46\n",
      "When input is tensor([25]), the target is 17\n",
      "When input is tensor([25, 17]), the target is 27\n",
      "When input is tensor([25, 17, 27]), the target is 10\n",
      "When input is tensor([25, 17, 27, 10]), the target is 0\n",
      "When input is tensor([25, 17, 27, 10,  0]), the target is 21\n",
      "When input is tensor([25, 17, 27, 10,  0, 21]), the target is 1\n",
      "When input is tensor([25, 17, 27, 10,  0, 21,  1]), the target is 54\n",
      "When input is tensor([25, 17, 27, 10,  0, 21,  1, 54]), the target is 39\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1337) # for reproducibility\n",
    "batch_size = 4 # how many independent sequences will we process in parallel?\n",
    "block_size = 8 # what is the maximum context length for predictions?\n",
    "\n",
    "def get_batch(split = 'train'):\n",
    "    \"\"\"generate a small batch of data of inputs x and targets y\"\"\"\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,)) # random starting indices\n",
    "    # print('ix:', ix.shape)\n",
    "\n",
    "    x = torch.stack([data[i:i + block_size] for i in ix]) # input context\n",
    "    y = torch.stack([data[i + 1:i + block_size + 1] for i in ix]) # targets are the same but shifted\n",
    "    return x, y\n",
    "\n",
    "xb, yb = get_batch('train')\n",
    "print('inputs:')\n",
    "print(xb.shape) # (batch_size, block_size)\n",
    "print(xb) # first two sequences in the batch\n",
    "\n",
    "print('targets:')\n",
    "print(yb.shape) # (batch_size, block_size)\n",
    "print(yb) # first two sequences in the batch\n",
    "\n",
    "print('*' * 50)\n",
    "\n",
    "for b in range(batch_size):\n",
    "    for t in range(block_size):\n",
    "        context = xb[b, :t + 1] # input context\n",
    "        target = yb[b, t] # target is the next character\n",
    "        print(f'When input is {context}, the target is {target}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a0aeb4f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[24, 43, 58,  5, 57,  1, 46, 43],\n",
      "        [44, 53, 56,  1, 58, 46, 39, 58],\n",
      "        [52, 58,  1, 58, 46, 39, 58,  1],\n",
      "        [25, 17, 27, 10,  0, 21,  1, 54]])\n"
     ]
    }
   ],
   "source": [
    "print(xb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "84c193e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: BigramLanguageModel(\n",
      "  (token_embedding_table): Embedding(65, 65)\n",
      ")\n",
      "out shape: torch.Size([32, 65])\n",
      "tensor(4.8786, grad_fn=<NllLossBackward0>)\n",
      "\n",
      "Sr?qP-QWktXoL&jLDJgOLVz'RIoDqHdhsV&vLLxatjscMpwLERSPyao.qfzs$Ys$zF-w,;eEkzxjgCKFChs!iWW.ObzDnxA Ms$3\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "torch.manual_seed(1337) # for reproducibility\n",
    "\n",
    "class BigramLanguageModel(nn.Module):\n",
    "    \"\"\"A bigram language model\"\"\"\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size) # embedding layer\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "        logits = self.token_embedding_table(idx) # (batch_size, block_size, vocab_size)\n",
    "\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B * T, C)\n",
    "            targets = targets.view(B * T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "\n",
    "        return logits, loss\n",
    "\n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        # idx is the (B, T) array of indices in the current context\n",
    "        for _ in range(max_new_tokens):\n",
    "            # get the predictions\n",
    "            logits, loss = self.forward(idx)\n",
    "            # focus only on the last time step\n",
    "            logits = logits[:, -1, :] # (batch_size, vocab_size)\n",
    "            # apply softmax to get probabilities\n",
    "            probs = F.softmax(logits, dim = -1) # (batch_size, vocab_size)\n",
    "            # sample from the distribution\n",
    "            idx_next = torch.multinomial(probs, num_samples = 1) # (batch_size, 1)\n",
    "            idx = torch.cat((idx, idx_next), dim = 1) # (B, T + 1)\n",
    "\n",
    "        return idx\n",
    "    \n",
    "model = BigramLanguageModel(n_embed)\n",
    "print('model:', model)\n",
    "logits, loss = model(xb, yb)\n",
    "print('out shape:', logits.shape) # (batch_size, block_size, vocab_size)\n",
    "print(loss)\n",
    "\n",
    "\n",
    "idx = torch.zeros((1, 1), dtype=torch.long) # start with a single token\n",
    "print(decode(model.generate(idx, max_new_tokens = 100)[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3cb1bc94",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr = 1e-3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "be284f30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, loss 4.704006195068359\n",
      "step 50, loss 4.6724138259887695\n",
      "step 100, loss 4.658433437347412\n",
      "step 150, loss 4.515491962432861\n",
      "step 200, loss 4.470171928405762\n",
      "step 250, loss 4.456277370452881\n",
      "step 300, loss 4.320702075958252\n",
      "step 350, loss 4.232100009918213\n",
      "step 400, loss 4.252743721008301\n",
      "step 450, loss 4.335793972015381\n",
      "step 500, loss 4.241008758544922\n",
      "step 550, loss 4.126287460327148\n",
      "step 600, loss 4.161406517028809\n",
      "step 650, loss 3.9944283962249756\n",
      "step 700, loss 4.044336795806885\n",
      "step 750, loss 3.8449132442474365\n",
      "step 800, loss 4.091874122619629\n",
      "step 850, loss 3.786890745162964\n",
      "step 900, loss 3.7458465099334717\n",
      "step 950, loss 3.6820056438446045\n",
      "step 1000, loss 3.7031264305114746\n",
      "step 1050, loss 3.6374661922454834\n",
      "step 1100, loss 3.7115283012390137\n",
      "step 1150, loss 3.5866546630859375\n",
      "step 1200, loss 3.6330997943878174\n",
      "step 1250, loss 3.4938368797302246\n",
      "step 1300, loss 3.422212600708008\n",
      "step 1350, loss 3.370107650756836\n",
      "step 1400, loss 3.4295449256896973\n",
      "step 1450, loss 3.5309958457946777\n",
      "step 1500, loss 3.4233598709106445\n",
      "step 1550, loss 3.3353159427642822\n",
      "step 1600, loss 3.3018524646759033\n",
      "step 1650, loss 3.270113706588745\n",
      "step 1700, loss 3.283510446548462\n",
      "step 1750, loss 3.2488248348236084\n",
      "step 1800, loss 3.188281774520874\n",
      "step 1850, loss 3.186506986618042\n",
      "step 1900, loss 3.2000553607940674\n",
      "step 1950, loss 3.1148767471313477\n",
      "step 2000, loss 3.1371781826019287\n",
      "step 2050, loss 3.1217265129089355\n",
      "step 2100, loss 3.0028276443481445\n",
      "step 2150, loss 3.083954095840454\n",
      "step 2200, loss 3.058077812194824\n",
      "step 2250, loss 3.084810733795166\n",
      "step 2300, loss 2.958632707595825\n",
      "step 2350, loss 2.9610488414764404\n",
      "step 2400, loss 2.981365919113159\n",
      "step 2450, loss 2.974921941757202\n",
      "step 2500, loss 2.9196817874908447\n",
      "step 2550, loss 2.865995407104492\n",
      "step 2600, loss 2.8414011001586914\n",
      "step 2650, loss 2.9619991779327393\n",
      "step 2700, loss 2.8905837535858154\n",
      "step 2750, loss 2.8619205951690674\n",
      "step 2800, loss 2.9735329151153564\n",
      "step 2850, loss 2.7729458808898926\n",
      "step 2900, loss 2.808624029159546\n",
      "step 2950, loss 2.7504312992095947\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "for steps in range(3000):\n",
    "    xb, yb = get_batch('train') # get a batch of data\n",
    "\n",
    "    logits, loss = model(xb, yb) # forward pass\n",
    "    optimizer.zero_grad(set_to_none = True) # zero the gradients\n",
    "    loss.backward() # backward pass\n",
    "    optimizer.step() # update the parameters\n",
    "\n",
    "    if steps % 50 == 0:\n",
    "        print(f'step {steps}, loss {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d8d08f3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Io lHX:w V;TingKA::\n",
      "AHA y'dx,ceanyenXAUEmy ngXXx:\n",
      "\n",
      "Bky$ghObsd d hso,\n",
      "WWAns thstheci.SlvmyDI'herca cerorabi-BD&yZIBad, 3CoyCOLq-PNau$Js t hes\n",
      "Iny vita;vnl wxaVTqinpgZJUzLgo?woced any,\n",
      "SPllonurno'XEE&y cellim:Bffr$LE:CEZve IZRerNIXSxqueseDus 3a!GXe MttNGR bdlaslgic3f CV;owdaNoghos seQJXRCotisire.d.\n",
      "BoigLOjK? wa f rellladdln IN soneay;\n",
      "th ClaHesingHephaPUGPH: zy iAL!?wszy thodsrd\n",
      "Whmaw:3SPRIURirowoXe d!\n",
      "JGSCUEToiMl,falYi-ma paWinonETZX.?Yhe 'Inenma!UCItltoevevjRqhr'ditheeSP,jupYzPanrcodg Nfujeor ui\n"
     ]
    }
   ],
   "source": [
    "idx = torch.zeros((1, 1), dtype=torch.long) # start with a single token\n",
    "print(decode(model.generate(idx, max_new_tokens = 500)[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ea3b3c6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 2])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1337) # for reproducibility\n",
    "B, T, C = 4, 8, 2 # batch size, block size, vocab size\n",
    "\n",
    "x = torch.randn(B, T, C)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "13ac257b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a: tensor([[1.0000, 0.0000, 0.0000],\n",
      "        [0.5000, 0.5000, 0.0000],\n",
      "        [0.3333, 0.3333, 0.3333]])\n",
      "b: tensor([[8., 6.],\n",
      "        [5., 2.],\n",
      "        [4., 4.]])\n",
      "c: tensor([[8.0000, 6.0000],\n",
      "        [6.5000, 4.0000],\n",
      "        [5.6667, 4.0000]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.tril(torch.ones((3, 3))) # lower triangular matrix\n",
    "a = a / a.sum(1, keepdim = True) # normalize each row\n",
    "b = torch.randint(0, 10, (3, 2)).float() # random matrix\n",
    "c = a @ b\n",
    "\n",
    "print('a:', a)\n",
    "print('b:', b)\n",
    "print('c:', c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d09e349d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 8, 2])\n",
      "tensor([[ 1.3488, -0.1396],\n",
      "        [ 0.8173,  0.4127],\n",
      "        [-0.1342,  0.4395],\n",
      "        [ 0.2711,  0.4774],\n",
      "        [ 0.2421,  0.0694],\n",
      "        [ 0.0084,  0.0020],\n",
      "        [ 0.0712, -0.1128],\n",
      "        [ 0.2527,  0.2149]])\n"
     ]
    }
   ],
   "source": [
    "# We want x[b, t] = mean_{i<=t} x[b, i]\n",
    "xbow = torch.zeros((B, T, C))\n",
    "\n",
    "for b in range(B):\n",
    "    for t in range(T):\n",
    "        xprev = x[b, :t + 1] # (t, C)\n",
    "        xbow[b, t] = torch.mean(xprev, 0) \n",
    "\n",
    "print(xbow.shape) # (B, T, C)\n",
    "print(xbow[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3d8e5326",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 8, 2])\n",
      "tensor([[ 1.3488, -0.1396],\n",
      "        [ 0.8173,  0.4127],\n",
      "        [-0.1342,  0.4395],\n",
      "        [ 0.2711,  0.4774],\n",
      "        [ 0.2421,  0.0694],\n",
      "        [ 0.0084,  0.0020],\n",
      "        [ 0.0712, -0.1128],\n",
      "        [ 0.2527,  0.2149]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = torch.tril(torch.ones((T, T))) # lower triangular matrix\n",
    "weights = weights / weights.sum(1, keepdim = True) # normalize each row\n",
    "xbow2 = weights @ x # (B, T, T) @ (B, T, C) -> (B, T, C)\n",
    "\n",
    "print(xbow2.shape) # (B, T, C)\n",
    "print(xbow2[1])\n",
    "\n",
    "torch.allclose(xbow, xbow2, atol=1e-6) # should be True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ee4cae2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tril = torch.tril(torch.ones((T, T)))\n",
    "weights = torch.zeros((T, T))\n",
    "weights = weights.masked_fill(tril == 0, float('-inf')) # fill upper triangular part with -inf\n",
    "weights = F.softmax(weights, dim = -1) # normalize each row\n",
    "xbow3 = weights @ x # (B, T, T) @ (B, T, C) -> (B, T, C)\n",
    "torch.allclose(xbow3, xbow2, atol=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f31221b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 8, 8])\n",
      "tensor(0.3386, grad_fn=<VarBackward0>) tensor(0.3164, grad_fn=<VarBackward0>) tensor(0.1201, grad_fn=<VarBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 16])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# version 4: self-attention\n",
    "torch.manual_seed(1337) # for reproducibility\n",
    "\n",
    "batch_size, block_size, n_embed = 4, 8, 32 # batch size, block size, vocab size\n",
    "x = torch.randn(batch_size, block_size, n_embed) # (B, T, C)\n",
    "\n",
    "\n",
    "# let's see a single head perform self-attention\n",
    "head_size = 16\n",
    "query = nn.Linear(n_embed, head_size, bias = False) # (C, H)\n",
    "key = nn.Linear(n_embed, head_size, bias = False) # (C, H)\n",
    "value = nn.Linear(n_embed, head_size, bias = False) # (C, H)\n",
    "\n",
    "k = key(x) # (B, T, H)\n",
    "q = query(x) # (B, T, H)\n",
    "\n",
    "weights = q @ k.transpose(-2, -1) * (head_size ** -0.5) # (B, T, H) @ (B, H, T) -> (B, T, T)\n",
    "print(weights.shape)\n",
    "\n",
    "print(k.var(), q.var(), weights.var()) # variance of k, q, and weights\n",
    "\n",
    "\n",
    "tril = torch.tril(torch.ones((block_size, block_size))) # lower triangular matrix\n",
    "# weights = torch.zeros((block_size, block_size))\n",
    "weights = weights.masked_fill(tril == 0, float('-inf')) # fill upper triangular part with -inf\n",
    "weights = F.softmax(weights, dim = -1) # normalize each\n",
    "\n",
    "v = value(x)\n",
    "out = weights @ v # (B, T, T) @ (B, T, C) -> (B, T, C)\n",
    "\n",
    "out.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d5bd8fb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.0700) tensor(1.0449) tensor(1.0918)\n"
     ]
    }
   ],
   "source": [
    "k = torch.randn(batch_size, block_size, head_size) # (B, T, H)\n",
    "q = torch.randn(batch_size, block_size, head_size) # (B, T,\n",
    "wei = q @ k.transpose(-2, -1) * head_size ** -0.5 # (B, T, H) @ (B, H, T) -> (B, T, T)\n",
    "\n",
    "print(q.var(), k.var(), wei.var()) # variance of q, k, and wei"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dlenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
